---
layout: post
title: pig
category: hadoop
tags: [hadoop, pig]
comments: false
---

# [pig]()

## 학습
* pig 이해

## 실습
* 접속
    - mapred-site.xml 설정
    <br> 1) [hadoop@nn01 ~]$ vi $HADOOP_HOME/etc/hadoop/mapred-site.xml
    ~~~shell
    <property>
    <name>mapreduce.jobhistory.address</name>
    <value>nn01:10020</value>
    </property>
    ~~~
    <br> 2) [hadoop@nn01 ~]$ cd $HADOOP_HOME/etc/hadoop
    <br> 3) [hadoop@nn01 hadoop]$ scp mapred-site.xml hadoop@dn01:/opt/hadoop/current/etc/hadoop/
    <br> 4) [hadoop@nn01 hadoop]$ scp mapred-site.xml hadoop@dn02:/opt/hadoop/current/etc/hadoop/

    - dn01, dn02의 mapred-site.xml 확인하기
    <br> 1) [hadoop@dn01 ~]$ vi $HADOOP_HOME/etc/hadoop/mapred-site.xml
    <br> 2) [hadoop@dn02 ~]$ vi $HADOOP_HOME/etc/hadoop/mapred-site.xml

    - stop, start 하기
    <br> 1) [hadoop@nn01 hadoop]$ stop-all.sh
    <br> 2) [hadoop@nn01 hadoop]$ start-all.sh
    <br> 3) [hadoop@nn01 hadoop]$ jps

    - historyserve 하기(mapreduce 가능하기위해)
    <br> 1) [hadoop@nn01 hadoop]$ cd $HADOOP_HOME/sbin
    <br> 2) [hadoop@nn01 sbin]$ mr-jobhistory-daemon.sh start historyserver
    <br> 3) [hadoop@nn01 sbin]$ jps
    ~~~shell
    29812 NameNode
    30166 ResourceManager
    30473 JobHistoryServer
    30010 SecondaryNameNode
    30510 Jps
    ~~~

    - mapreduce 접속
    <br> 1) [hadoop@dn01 ~]$ pig -x mapreduce
    <br> 2) grunt> groceries = load 'hdfs://nn01:9000/input/pig_data/groceries.csv' using PigStorage(',');
    <br> 3) grunt> dump groceries
    <br> 4) grunt> store groceries into '/output/pig_data/store_dir' using PigStorage();

    - output 확인
    <br> 1) [hadoop@dn02 ~]$ ssh dn01
    <br> 2) [hadoop@dn01 ~]$ hdfs dfs -ls /output/pig_data/store_dir
    <br> 3) [hadoop@dn01 ~]$ hdfs dfs -cat /output/pig_data/store_dir/part-m-00000

* 스키마 구조
    - groceries.csv 처리
    <br> 1) [hadoop@dn01 ~]$ pig -x local
    <br> 2) grunt> groceries = load 'file:///home/hadoop/pig_data/groceries.csv' using PigStorage(',')
    <br> 3) >> as (
    <br> 4) >> order_id:chararray,
    <br> 5) >> location:chararray,
    <br> 6) >> product:chararray,
    <br> 7) >> day:datetime,
    <br> 8) >> revenue:double);
    <br> 10) grunt> describe groceries;
    <br> 11) grunt> products = foreach groceries generate location, product, day;
    <br> 12) grunt> dump products
    <br> 13) grunt> store products into 'file:///home/hadoop/pig_data/output/store_dir' using PigStorage();

    - 처리 확인
    <br> 1) [hadoop@dn02 ~]$ ssh dn01
    <br> 2) [hadoop@dn01 ~]$ ls /home/hadoop/pig_data/output/store_dir
    <br> 3) [hadoop@dn01 ~]$ cat /home/hadoop/pig_data/output/store_dir

    - limit 확인
    <br> 4) grunt> groceries_sub = limit groceries 5;
    <br> 5) grunt> dump groceries_sub

* 복합 자료형
    - student_subjects.txt 처리
    <br> 1) grunt> student_subjects = load 'file:///home/hadoop/pig_data/data/student_subjects.txt' 
    <br> 2) >> as (
    <br> 3) >> student_id:chararray,
    <br> 4) >> name:chararray,
    <br> 5) >> grade:int,
    <br> 6) >> subject1:chararray,
    <br> 7) >> subject2:chararray,
    <br> 8) >> subject3:chararray);
    <br> 9) dump student_subjects
    
    - bag 처리
    <br> 1) grunt> student_subjects2 = foreach student_subjects generate name, TOBAG(subject1, subject2, subject3) as subject;
    <br> 2) grunt> student_subject3 = foreach student_subjects2 generate subject;
    <br> 3) dump student_subjects3

    - student_marks.txt
    <br> 1) grunt> student_marks = load 'file:///home/hadoop/pig_data/data/student_marks.txt'
    <br> 2) >> as (
    <br> 3) >> student_id:chararray,
    <br> 4) >> name:chararray,
    <br> 5) >> grade:int,
    <br> 6) >> marks:map[int]);
    <br> 7) grunt> student_marks2 = foreach student_marks generate name, marks#'Math';
    <br> 8) grunt> dump student_marks2

    - map 처리
    <br> 1) grunt> student_marks3 = foreach student_marks generate student_id, TOMAP(name, grade);
    <br> 2) grunt> dump student_marks3

    - students.txt 처리
    <br> 1) grunt> students = load 'file:///home/hadoop/pig_data/data/students.txt'
    <br> 2) >> as (
    <br> 3) >> stu_id:chararray,
    <br> 4) >> name:chararray,
    <br> 5) >> grade:int,
    <br> 6) >> contact:tuple(addr:chararray, tel:chararray));
    <br> 7) grunt> dump student

    - tuple 처리
    <br> 1) grunt> students2 = foreach students generate name, contact.tel;
    <br> 2) grunt> dump students2

    - flatten 처리(tuple을 풀어줌)
    <br> 1) grunt> students3 = foreach student generate stu_id, name, grade, flatten(contact);
    <br> 2) grunt> dump students3

    - wordcount 처리
    <br> 1) grunt> A = load 'file:///opt/hadoop/current/README.txt';
    <br> 2) grunt> dump A
    <br> 3) grunt> B = foreach A generate flatten(TOKENIZE((chararray)$0)) as word;
    <br> 4) grunt> dump B
    <br> 5) grunt> C = group B by word;
    <br> 6) grunt> dump C
    <br> 7) grunt> D = foreach C generate group as word, COUNT($1) as count;
    <br> 8) grunt> dump D 

* Function
    - orders.json
    <br> 1) grunt> orders = load 'file:///home/hadoop/pig_data/data/orders.json' using JsonLoader('
    <br> 2) >> order_id:chararray, 
    <br> 3) >> username:chararray, 
    <br> 4) >> product:chararray, 
    <br> 5) >> quantity:int, 
    <br> 6) >> amount:double, 
    <br> 7) >> order_date:chararray, 
    <br> 8) >> zipcode:chararray');
    <br> 9) grunt> dump orders
    <br> 10) grunt> orders2 = foreach orders generate username, product, quantity*amount as total;
    <br> 11) grunt> dump orders2

    - ROUND함수 함수
    <br> grunt> orders2 = foreach orders generate ROUND(quantity*amount) as total

    - SUBSTING() 함수
    <br> grunt> orders2 = foreach orders generate SUBSTRING(order_id, 1, 3);

    - REPLACE 함수
    <br> grunt> orders2 = foreach orders generate REPLACE(order_id,'o', 'order');

    - 주문번호로 정렬
    <br> grunt> result = order orders by order_id DESC;

    - 총가격 순으로 정렬하고 상위 5개 출력
    <br> grunt> result = foreach orders generate product, username, ROUND(quantity*amount) as total;
    <br> grunt> result2 = order result by total DESC;
    <br> grunt> result3 = limit result2 5; 

    - 주문 날짜의 월단위로 정렬(getMonth() 함수)
    <br> grunt> result = foreach orders generate product, username, ToDate(order_date, 'MM-dd-yyyy') as date;
    <br> grunt> result2 = foreach result generate product, username, GetMonth(date) as month;
    <br> grunt> result3 = order result2 by month;
    <br> grunt> dump result3

* Filter
    - 수량이 없는 튜플 제외하기
    <br> grunt> result = filter orders by quantity > 0;

    - 주문번호가 'o4'이상인 튜플들 추출
    <br> grunt> result2 = filter result by order_id >= 'o4';

    - 상품명이 'tv'로 끝나는 튜플들 추출
    <br> grunt> result = filter orders by product matches '.*tv';

    - 상품명이 'speakers'가 포함된 튜플들 추출
    <br> grunt> result = filter orders by product matches '.*speakers';

 * Split
    - 개수가 1인 bag와 1초과인 bag으로 나누기 
    <br> 1) grunt> split orders into result_1 if(quantity == 1), result_more if(quantity > 1);
    <br> 2) grunt> dump result_1
    <br> 3) grunt> dump result_more

    - 사용자명이 있는 bag와 사용자명이 없는 bag으로 나누기
    <br> 1) grunt> split orders into result_notnull if(username is not null), result_null if(username is null);
    <br> 2) grunt> dump result_notnull;
    <br> 3) grunt> dump result_null;

* Distinct(중복제거)
    - orders_duplicates.json
    <br> 1) grunt> rep_orders = load 'file:///home/hadoop/pig_data/data/orders_duplicates.json' using JsonLoader('
    <br> 2) >> order_id: chararray,
    <br> 3) >> username: chararray,
    <br> 4) >> product: chararray,
    <br> 5) >> quantity: int,
    <br> 6) >> amount: double,
    <br> 7) >> order_date: chararray,
    <br> 8) >> zipcode: chararray');
    <br> 9) grunt> dump rep_orders;
    <br> 10) grunt> result = distinct rep_orders;
    <br> 11) grunt> dump result;

* Join
    - emp.csv 파일 로드하여 변수 emp 저장
    <br> grunt> emp = load 'file:///home/hadoop/pig_data/data/emp/emp.csv' using PigStorage(',');

    - dept.csv 파일 로드하여 변수 dept 저장
    <br> grunt> dept = load 'file:///home/hadoop/pig_data/data/emp/dept.csv' using PigStorage(',');

    - 두 bag을 조인하기
    <br> grunt> emp_join = JOIN emp BY $7, dept BY $2;

    - 조인 bag에서 월급이 2000 초과한 내역을 월급순으로 정렬하여 출력(filter 이용)
    <br> 1) grunt> emp_join = JOIN emp BY $7, dept BY $2;
    <br> 2) grunt> result = FILTER emp_join BY $5 > 2000;
    <br> 3) grunt> result2 = ORDER result BY $5 DESC;
    <br> 4) grunt> dump result2;

## 정리
* Pig 명령어
    - DUMP : 결과를 화면에 출력 가능
    - STORE : 결과를 파일로 저장 가능
    - DESCRIBE : 데이터 구조에 대한 정보를 보여줌
* FOREACH
    - 필요한 컬럼들만 결과로 만들기
* DISTINCT
    - Bag안에 중복 튜플들을 삭제
* LIMI
    - 출력되는 튜플의 개수 제한
* 스키마
    - 스카마가 없으면 describe 구조 없음, 컬럼을 $숫자로 추출
    - 스키마가 있으면 describe 구조 확인, 컬럼명으로 추출
* 복합자료형
    - bag
    - map
    - tuple